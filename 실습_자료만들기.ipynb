{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습 자료만들기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGyNoiKAo5U2ng4+5g1r/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/NLP_study/blob/main/%EC%8B%A4%EC%8A%B5_%EC%9E%90%EB%A3%8C%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExzFv22mj_6v"
      },
      "source": [
        "cd /content/drive/My Drive/ml/nlp/book/ch6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r0F3jaxkH0U"
      },
      "source": [
        "!pip install -q konlpy\n",
        "!pip install -q preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sWLSSYE8oxo"
      },
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from konlpy.tag import Twitter\n",
        "import pandas as pd\n",
        "import enum\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from preprocessing import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYkwqfgSv2n"
      },
      "source": [
        "SEED_NUM = 1234\n",
        "tf.random.set_seed(SEED_NUM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgmrxheAXKw4"
      },
      "source": [
        "index_inputs = np.load(open(TRAIN_INPUTS, 'rb'))\n",
        "index_outputs = np.load(open(TRAIN_OUTPUTS , 'rb'))\n",
        "index_targets = np.load(open(TRAIN_TARGETS , 'rb'))\n",
        "prepro_configs = json.load(open(DATA_CONFIGS, 'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF1udyFtSv9B"
      },
      "source": [
        "char2idx = prepro_configs['char2idx']\n",
        "end_index = prepro_configs['end_symbol']\n",
        "vocab_size = prepro_configs['vocab_size']\n",
        "\n",
        "model_name = 'transformer'\n",
        "\n",
        "# hyperparameters일부 정리\n",
        "BATCH_SIZE = 64\n",
        "MAX_SEQUENCE = 25\n",
        "EPOCHS = 35\n",
        "VALID_SPLIT = 0.1\n",
        "\n",
        "# Transformer의 arguments 정의\n",
        "kargs = {'model_name': model_name,\n",
        "         'num_layers': 2,\n",
        "         'd_model': 512,\n",
        "         'num_heads': 8,\n",
        "         'dff': 2048,\n",
        "         'input_vocab_size': vocab_size,\n",
        "         'target_vocab_size': vocab_size,\n",
        "         'maximum_position_encoding': MAX_SEQUENCE,\n",
        "         'end_token_idx': char2idx[end_index],\n",
        "         'rate': 0.1\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDRrhhUTdrPk"
      },
      "source": [
        "## mask 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTOfyv7SwBg"
      },
      "source": [
        "# sequence를 받아서 패딩\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32) # seq중 0을 기준으로 bool로 바꾼후 0으로 casting\n",
        "\n",
        "  return seq[:, tf.mewaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpyOPIfjOgM4"
      },
      "source": [
        "def create_look_ahead_mask(size): # mask의 사이즈를 parameter로 받음\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones(size, size), -1, 0) # 하삼각행렬로 변환\n",
        "\n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pFhs4FaOgPQ"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  enc_padding_mask = create_padding_mask(inp) # 인코더 패딩 마스크\n",
        "  dec_padding_mask = create_padding_mask(inp) # 디코더 패딩 마스크\n",
        "\n",
        "  # 디코더에 대한 마스크는 하삼각행렬을...\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fln-Db3Vc-l0"
      },
      "source": [
        "## positional encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1e51nKOgT9"
      },
      "source": [
        "# 위치별 각도를 얻는 함수\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * i / 2) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWwMR39lOgYq"
      },
      "source": [
        "# 최종 포지셔널 인코딩\n",
        "def positional_encoding(position, d_model): # position과 d_model을 parameter로 받음\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # 짝수는 sine 함수를 이용한 pos encoding\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # 홀수는 cosine 함수를 이용한 pos encoding\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaixs, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype = tf.float32) # pos encoding을 실수로 casting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXlstOwAie8B"
      },
      "source": [
        "## Scaled dot product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcNwJXqBSv0B"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b = True) # key에 대해서 matmul 이전 transposed\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape()[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9) # 큰 음수를 곱해줘서 mask화 시키도록함....\n",
        "\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # softmax 적용\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # matmul 적용\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEjfhFI2ih2Q"
      },
      "source": [
        "## Multihead Attention\n",
        "참고: keras 2.4에 multihead attention layer가 release될 예정임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQwrUQM-s2N4"
      },
      "source": [
        "'''\n",
        "1. WQ, WK, WV에 해당하는 d_model 크기의 밀집층(Dense layer)을 지나게한다.\n",
        "2. 지정된 헤드 수(num_heads)만큼 나눈다(split).\n",
        "3. 스케일드 닷 프로덕트 어텐션.\n",
        "4. 나눠졌던 헤드들을 연결(concatenatetion)한다.\n",
        "5. WO에 해당하는 밀집층을 지나게 한다.\n",
        "'''\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = kargs['num_heads']\n",
        "        self.d_model = kargs['d_model']\n",
        "\n",
        "        assert self.d_model % self.num_heads == 0\n",
        "\n",
        "        # d_model을 num_heads로 나눈값으로 qkv를 정하기\n",
        "        # 논문에서는 64\n",
        "        self.depth = self.d_model // self.num_heads\n",
        "\n",
        "        # wq wk wv - qkv를 만들기 위한 가중치 행렬\n",
        "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
        "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
        "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
        "\n",
        "        # w0\n",
        "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
        "\n",
        "    # num_heads 개수만큼 q, k, v를 split\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, query_seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, key_seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, value_seq_len, d_model)\n",
        "\n",
        "        # depth = d_moel / num_heads\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, query_seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, key_seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, value_seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, \n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgRS_WA2imby"
      },
      "source": [
        "## Feed forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXONtsgpSvrH"
      },
      "source": [
        "def point_wise_feed_forward_network(**kargs):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff:2048)\n",
        "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7mr61kuisDG"
      },
      "source": [
        "# Encoder layer\n",
        "(MHA, FFN, norm, dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s319JWynirx-"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(**kargs)\n",
        "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        '''multihead attention \n",
        "           - dropout\n",
        "           - add & normalization \n",
        "           \n",
        "           - feed forward network \n",
        "           - dropout\n",
        "           - add & normalization'''\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFcOKosViuhU"
      },
      "source": [
        "## Decoder layer\n",
        "(MHA, FFN, norm, dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4dKxvS4jEC8"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(**kargs)\n",
        "        self.mha2 = MultiHeadAttention(**kargs)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "        '''masked multihead attention \n",
        "           - dropout\n",
        "           - add & normalization \n",
        "           \n",
        "           - multihead attention \n",
        "           - dropout\n",
        "           - add & normalization \n",
        "\n",
        "           - feed forward network \n",
        "           - dropout\n",
        "           - add & normalization'''\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK7ofTEdjfrK"
      },
      "source": [
        "## Encoder\n",
        "(Embedding, ENC_layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvg0hvMriuUd"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = kargs['d_model']\n",
        "        self.num_layers = kargs['num_layers']\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
        "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], \n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(**kargs) \n",
        "                           for _ in range(self.num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "    def call(self, x, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        '''\n",
        "          embedding\n",
        "          - positional encoding\n",
        "          - dropout\n",
        "          - encoding layers * num_layer(여기서는 2r개의 layer)\n",
        "        '''\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_V0gW1pjpb8"
      },
      "source": [
        "## Decoder\n",
        "(Embedding, DEC_layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrWT3eG2jp6x"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kargs):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = kargs['d_model']\n",
        "        self.num_layers = kargs['num_layers']\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n",
        "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(**kargs) \n",
        "                           for _ in range(self.num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
        "\n",
        "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        '''\n",
        "          word embedding\n",
        "          positional embedding\n",
        "          dropout\n",
        "          decoder_layers\n",
        "        '''\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed7d0S4pkX7t"
      },
      "source": [
        "## Transformer\n",
        "(Encoder, Decoder, final_layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnUwBcPWkXpV"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, **kargs):\n",
        "        super(Transformer, self).__init__(name=kargs['model_name'])\n",
        "        self.end_token_idx = kargs['end_token_idx']\n",
        "        \n",
        "        self.encoder = Encoder(**kargs)\n",
        "        self.decoder = Decoder(**kargs)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
        "\n",
        "    # 학습시 사용\n",
        "    def call(self, x):\n",
        "        inp, tar = x\n",
        "\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
        "        enc_output = self.encoder(inp, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, _ = self.decoder(\n",
        "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    # 추론시 사용\n",
        "    def inference(self, x):\n",
        "        inp = x\n",
        "        tar = tf.expand_dims([STD_INDEX], 0)\n",
        "\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)        \n",
        "        enc_output = self.encoder(inp, enc_padding_mask)\n",
        "        \n",
        "        predict_tokens = list()\n",
        "        for t in range(0, MAX_SEQUENCE):\n",
        "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
        "            final_output = self.final_layer(dec_output)\n",
        "            outputs = tf.argmax(final_output, -1).numpy()\n",
        "            pred_token = outputs[0][-1]\n",
        "            if pred_token == self.end_token_idx:\n",
        "                break\n",
        "            predict_tokens.append(pred_token)\n",
        "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
        "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
        "            \n",
        "        return predict_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvAa83rjk9Vq"
      },
      "source": [
        "## loss function & accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntJ6tzkakXdO"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "def loss(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "    pred *= mask    \n",
        "    acc = train_accuracy(real, pred)\n",
        "\n",
        "    return tf.reduce_mean(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzpTQTCBlFbD"
      },
      "source": [
        "## early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_ByrLQVABz"
      },
      "source": [
        "# overfitting을 막기 위한 ealrystop 추가\n",
        "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
        "# min_delta: 종료시킬 delta의 최솟값 (acc가 최소 0.0001이상 상승해야 함)\n",
        "# patience: 상승이 없어도... 버틸수 있도록.. 왔다갔다하니까 (patience = 1, 1번 이상 상승이 없으면 종료)\n",
        "\n",
        "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 위치에 대한 확인\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
        "else:\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
        "    \n",
        "\n",
        "cp_callback = ModelCheckpoint(\n",
        "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnmGKPBqU_eg"
      },
      "source": [
        "## model compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKxGJdfCU_e7"
      },
      "source": [
        "history = model.fit([index_inputs, index_outputs], index_targets, \n",
        "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Doixi7_KVFd2"
      },
      "source": [
        "## model load & results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y188WrPWlFyG"
      },
      "source": [
        "DATA_OUT_PATH = 'output/'\n",
        "SAVE_FILE_NM = 'weights.h5'\n",
        "\n",
        "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NM))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHjSf8-tVD6O"
      },
      "source": [
        "char2idx = prepro_configs['char2idx']\n",
        "idx2char = prepro_configs['idx2char']\n",
        "\n",
        "text = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
        "test_index_inputs, _ = enc_processing([text], char2idx)\n",
        "outputs = model.inference(test_index_inputs)\n",
        "\n",
        "print(' '.join([idx2char[str(o)] for o in outputs]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}