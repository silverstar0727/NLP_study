{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch4_LogisticRegression_TFidf.ipynb",
      "provenance": [],
      "mount_file_id": "1a0sBi8L0hZr0R5l3b6nBNj26STh1fH_n",
      "authorship_tag": "ABX9TyM2wLiYesC8yrI1rLwlTvFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/NLP_study/blob/main/ch4_LogisticRegression_TFidf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pBN2_dIFMxO",
        "outputId": "873e2dfb-0b7d-40b5-b410-cd231d1bc542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My Drive/kaggle_nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kaggle_nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQCKapNeGyuk"
      },
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2234WSEGboP"
      },
      "source": [
        "# TF-IDF를이용한 모델 구현\n",
        "\n",
        "# scikit learn의 TfidfVectorizer를 사용 (텍스트 형태의 데이터를 인풋)\n",
        "DATA_IN_PATH = 'after_preprocessing/'\n",
        "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
        "\n",
        "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)\n",
        "\n",
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-jRZfUjGiGG"
      },
      "source": [
        "# min_df: 설정한 값보다 작게 나오면 벡터화 과정에서 제외\n",
        "# analyzer: 벡터화 단위 여기서는 문자 하나단위 (word는 단어 단위)\n",
        "# sublinear_tf: 단어의 빈도수에 대한 스무딩(등장 카운트에 더해줌으로써 0이되는 것을 방지)\n",
        "# ngram_range: 빈도의 기본 단위를 어느 범위의 ngram으로 설정할 지 정하는 것\n",
        "# max_features: 각 벡터의 최대길이 설정\n",
        "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer = 'char', sublinear_tf = True, \n",
        "                             ngram_range = (1, 3), max_features = 5000)\n",
        "X = vectorizer.fit_transform(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOohjLmFGiIT"
      },
      "source": [
        "# 학습과 검증 데이터 셋 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 42 # random seed를 고정\n",
        "TEST_SPLIT = 0.2 # 20퍼를 evaluate data set으로 설정\n",
        "\n",
        "y = np.array(sentiments) # 정답 배열\n",
        "\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size = TEST_SPLIT,\n",
        "                                                    random_state = RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47vm3FINGiKV",
        "outputId": "83b256ff-e425-409d-8f73-e3c25d6f9135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# 모델선언 및 학습(logistic regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 로지스틱 회귀 객체를 생성\n",
        "# class_weight: 각 라벨에 대해 균형있게 학습하도록 함\n",
        "lgs = LogisticRegression(class_weight = 'balanced')\n",
        "lgs.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbfRyeFcGiMo",
        "outputId": "613d120a-82ae-47e1-9718-dcf21d0688de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluation data를 이용한 모델 평가\n",
        "print(\"Accuracy: %f\".format(lgs.score(X_eval, y_eval)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: %f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1K_gWvLGiDQ"
      },
      "source": [
        "TEST_CLEAN_DATA = 'test_clean.csv'\n",
        "\n",
        "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELhp9zzxHHXf"
      },
      "source": [
        "testDataVecs = vectorizer.transform(test_data['review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XCvJashHHby",
        "outputId": "4e76bca4-92ce-499d-8e3e-89f4abe72c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_predicted = lgs.predict(testDataVecs)\n",
        "print(test_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEl4NQLrHHVN"
      },
      "source": [
        "DATA_OUT_PATH = 'output/'\n",
        "\n",
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "  os.makedirs(DATA_OUT_PATH)\n",
        "\n",
        "ids = list(test_data['id'])\n",
        "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
        "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_tfidf_answer.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apgQneXLJ9t-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
