{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch4_LogisticRegression_word2vec.ipynb",
      "provenance": [],
      "mount_file_id": "1ehFZB0tenh7v5pgVI5FZryVl3ttqka9G",
      "authorship_tag": "ABX9TyPxsnZnmtUO+DSGWW3d2/49",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/NLP_study/blob/main/ch4_LogisticRegression_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K96KommlKeVa",
        "outputId": "5e79daee-e75e-4fea-d411-2f3516d5355b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My Drive/kaggle_nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kaggle_nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHOpoh6KJ0x"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2-3Mo1RKyEj"
      },
      "source": [
        "DATA_IN_PATH = 'after_preprocessing/'\n",
        "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
        "\n",
        "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)\n",
        "\n",
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])\n",
        "\n",
        "sentences = [] # list에 review를 단어로 구분하여 담음\n",
        "for review in reviews:\n",
        "  sentences.append(review.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ71cxkSKyCX"
      },
      "source": [
        "# 학습시 필요한 파라미터\n",
        "num_features = 300 # 워드 벡터 특징값 수(임베딩 된 차원을 정함)\n",
        "min_word_count = 40 # 단어에 대한 최소 빈도 개수(의미있는 단어만 학습)\n",
        "num_workers = 4 # 프로세스 개수\n",
        "context = 10 # 컨텍스트 윈도우 크기\n",
        "downsampling = 10e-3 # 다운 샘플링 비율"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8dP6opKKyAN"
      },
      "source": [
        "# word2vec을 gensim을 이용하여 학습\n",
        "import logging\n",
        "logging.basicConfig(format = '%(asctime)s : %(message)s', level = logging.INFO) # 진행상황 확인"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG8gXBe5Kx9n",
        "outputId": "2005f586-5c58-4d27-8a20-21d55b304434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
        "           size=num_features, min_count = min_word_count, \\\n",
        "            window = context, sample = downsampling)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-30 04:03:39,347 : collecting all words and their counts\n",
            "2020-09-30 04:03:39,350 : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-09-30 04:03:39,676 : PROGRESS: at sentence #10000, processed 1205223 words, keeping 51374 word types\n",
            "2020-09-30 04:03:39,983 : PROGRESS: at sentence #20000, processed 2396605 words, keeping 67660 word types\n",
            "2020-09-30 04:03:40,143 : collected 74065 word types from a corpus of 2988089 raw words and 25000 sentences\n",
            "2020-09-30 04:03:40,144 : Loading a fresh vocabulary\n",
            "2020-09-30 04:03:40,209 : effective_min_count=40 retains 8160 unique words (11% of original 74065, drops 65905)\n",
            "2020-09-30 04:03:40,210 : effective_min_count=40 leaves 2627273 word corpus (87% of original 2988089, drops 360816)\n",
            "2020-09-30 04:03:40,242 : deleting the raw counts dictionary of 74065 items\n",
            "2020-09-30 04:03:40,245 : sample=0.01 downsamples 0 most-common words\n",
            "2020-09-30 04:03:40,253 : downsampling leaves estimated 2627273 word corpus (100.0% of prior 2627273)\n",
            "2020-09-30 04:03:40,286 : estimated required memory for 8160 words and 300 dimensions: 23664000 bytes\n",
            "2020-09-30 04:03:40,287 : resetting layer weights\n",
            "2020-09-30 04:03:42,379 : training model with 4 workers on 8160 vocabulary and 300 features, using sg=0 hs=0 sample=0.01 negative=5 window=10\n",
            "2020-09-30 04:03:43,411 : EPOCH 1 - PROGRESS: at 12.22% examples, 313535 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:44,428 : EPOCH 1 - PROGRESS: at 23.56% examples, 306579 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:45,434 : EPOCH 1 - PROGRESS: at 35.08% examples, 305516 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:46,440 : EPOCH 1 - PROGRESS: at 47.12% examples, 307192 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-30 04:03:47,465 : EPOCH 1 - PROGRESS: at 59.25% examples, 308793 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:48,483 : EPOCH 1 - PROGRESS: at 71.62% examples, 310322 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:49,514 : EPOCH 1 - PROGRESS: at 83.97% examples, 310748 words/s, in_qsize 8, out_qsize 0\n",
            "2020-09-30 04:03:50,556 : EPOCH 1 - PROGRESS: at 96.42% examples, 310518 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:50,782 : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-30 04:03:50,788 : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-30 04:03:50,790 : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-30 04:03:50,800 : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-30 04:03:50,801 : EPOCH - 1 : training on 2988089 raw words (2627273 effective words) took 8.4s, 312164 effective words/s\n",
            "2020-09-30 04:03:51,881 : EPOCH 2 - PROGRESS: at 12.22% examples, 299993 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:52,928 : EPOCH 2 - PROGRESS: at 24.99% examples, 311940 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:53,948 : EPOCH 2 - PROGRESS: at 37.39% examples, 316106 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:54,971 : EPOCH 2 - PROGRESS: at 50.34% examples, 320161 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:55,972 : EPOCH 2 - PROGRESS: at 63.02% examples, 322380 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:57,016 : EPOCH 2 - PROGRESS: at 75.63% examples, 321647 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:58,053 : EPOCH 2 - PROGRESS: at 88.58% examples, 322582 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:03:58,870 : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-30 04:03:58,876 : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-30 04:03:58,885 : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-30 04:03:58,906 : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-30 04:03:58,908 : EPOCH - 2 : training on 2988089 raw words (2627273 effective words) took 8.1s, 324357 effective words/s\n",
            "2020-09-30 04:03:59,936 : EPOCH 3 - PROGRESS: at 11.87% examples, 310282 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:00,955 : EPOCH 3 - PROGRESS: at 23.96% examples, 311591 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:01,986 : EPOCH 3 - PROGRESS: at 36.05% examples, 311991 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-30 04:04:03,000 : EPOCH 3 - PROGRESS: at 48.74% examples, 315724 words/s, in_qsize 7, out_qsize 1\n",
            "2020-09-30 04:04:04,024 : EPOCH 3 - PROGRESS: at 61.61% examples, 319131 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:05,055 : EPOCH 3 - PROGRESS: at 73.60% examples, 316772 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:06,055 : EPOCH 3 - PROGRESS: at 86.28% examples, 318820 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:07,064 : EPOCH 3 - PROGRESS: at 98.46% examples, 317820 words/s, in_qsize 4, out_qsize 1\n",
            "2020-09-30 04:04:07,088 : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-30 04:04:07,094 : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-30 04:04:07,102 : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-30 04:04:07,128 : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-30 04:04:07,130 : EPOCH - 3 : training on 2988089 raw words (2627273 effective words) took 8.2s, 319865 effective words/s\n",
            "2020-09-30 04:04:08,148 : EPOCH 4 - PROGRESS: at 11.52% examples, 302142 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-30 04:04:09,156 : EPOCH 4 - PROGRESS: at 23.57% examples, 310795 words/s, in_qsize 8, out_qsize 1\n",
            "2020-09-30 04:04:10,200 : EPOCH 4 - PROGRESS: at 36.36% examples, 315908 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:11,235 : EPOCH 4 - PROGRESS: at 48.74% examples, 314948 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:12,339 : EPOCH 4 - PROGRESS: at 61.94% examples, 315741 words/s, in_qsize 7, out_qsize 2\n",
            "2020-09-30 04:04:13,371 : EPOCH 4 - PROGRESS: at 74.95% examples, 317704 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:14,391 : EPOCH 4 - PROGRESS: at 87.86% examples, 319961 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:15,309 : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-30 04:04:15,318 : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-30 04:04:15,324 : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-30 04:04:15,336 : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-30 04:04:15,337 : EPOCH - 4 : training on 2988089 raw words (2627273 effective words) took 8.2s, 320529 effective words/s\n",
            "2020-09-30 04:04:16,353 : EPOCH 5 - PROGRESS: at 11.52% examples, 302189 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:17,359 : EPOCH 5 - PROGRESS: at 23.92% examples, 315527 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:18,373 : EPOCH 5 - PROGRESS: at 36.03% examples, 316337 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:19,392 : EPOCH 5 - PROGRESS: at 48.39% examples, 316504 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-30 04:04:20,401 : EPOCH 5 - PROGRESS: at 60.58% examples, 317193 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:21,451 : EPOCH 5 - PROGRESS: at 73.60% examples, 318501 words/s, in_qsize 7, out_qsize 0\n",
            "2020-09-30 04:04:22,466 : EPOCH 5 - PROGRESS: at 86.28% examples, 319651 words/s, in_qsize 6, out_qsize 1\n",
            "2020-09-30 04:04:23,463 : worker thread finished; awaiting finish of 3 more threads\n",
            "2020-09-30 04:04:23,465 : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-09-30 04:04:23,479 : EPOCH 5 - PROGRESS: at 99.64% examples, 321940 words/s, in_qsize 1, out_qsize 1\n",
            "2020-09-30 04:04:23,481 : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-09-30 04:04:23,508 : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-09-30 04:04:23,509 : EPOCH - 5 : training on 2988089 raw words (2627273 effective words) took 8.2s, 321839 effective words/s\n",
            "2020-09-30 04:04:23,510 : training on a 14940445 raw words (13136365 effective words) took 41.1s, 319390 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLKEhqGXKx33"
      },
      "source": [
        "def get_features(words, model, num_features):\n",
        "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
        "\n",
        "    num_words = 0\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "\n",
        "    for w in words:\n",
        "        if w in index2word_set:\n",
        "            num_words += 1\n",
        "            feature_vector = np.add(feature_vector, model[w])\n",
        "\n",
        "    feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huWBkeMvLMDi"
      },
      "source": [
        "def get_dataset(reviews, model, num_features):\n",
        "    dataset = list()\n",
        "\n",
        "    for s in reviews:\n",
        "        dataset.append(get_features(s, model, num_features))\n",
        "\n",
        "    reviewFeatureVecs = np.stack(dataset)\n",
        "    \n",
        "    return reviewFeatureVecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-cmz0XJLVHK",
        "outputId": "48c72544-cc87-4506-be9c-d87f173446d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "test_data_vecs = get_dataset(sentences, model, num_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W29qKTQ-MXe7"
      },
      "source": [
        "TEST_SPLIT = 0.2\n",
        "RANDOM_SEED = 142"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjms361cLKL_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X = test_data_vecs\n",
        "y = np.array(sentiments)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnk-r73mLTGK",
        "outputId": "5827b0a3-ef17-42d3-94f9-4321e480ebc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lgs = LogisticRegression(class_weight='balanced')\n",
        "lgs.fit(X_train, y_train)\n",
        "\n",
        "predicted = lgs.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoRe1XTWLRvR",
        "outputId": "bd08bdc6-3b5a-49bd-c3f8-468907e66f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "print(\"------------\")\n",
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))  #checking the accuracy\n",
        "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
        "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
        "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
        "print(\"AUC: %f\" % auc)\n",
        "\n",
        "TEST_CLEAN_DATA = 'test_clean.csv'\n",
        "\n",
        "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)\n",
        "\n",
        "test_review = list(test_data['review'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------\n",
            "Accuracy: 0.859000\n",
            "Precision: 0.862922\n",
            "Recall: 0.860556\n",
            "F1-Score: 0.861738\n",
            "AUC: 0.935323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwaR9R6qLKJi",
        "outputId": "5c0f573b-05d3-4156-8364-7ae0f009440b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "test_sentences = list()\n",
        "for review in test_review:\n",
        "    test_sentences.append(review.split())\n",
        "\n",
        "test_data_vecs = get_dataset(test_sentences, model, num_features)\n",
        "\n",
        "test_predicted = lgs.predict(test_data_vecs)\n",
        "\n",
        "ids = list(test_data['id'])\n",
        "\n",
        "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuTZIsdgLZOi"
      },
      "source": [
        "DATA_OUT_PATH = 'output/'\n",
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "    os.makedirs(DATA_OUT_PATH)\n",
        "\n",
        "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_w2v_answer.csv', index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rarquisVLhwE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
