{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습 자료만들기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcyy/rApeH0WqgfAYAhu+Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/NLP_study/blob/main/%EC%8B%A4%EC%8A%B5_%EC%9E%90%EB%A3%8C%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAQYTtsYSRzv",
        "outputId": "92c495e2-5618-4b05-8f52-b112a5294bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from konlpy.tag import Twitter\n",
        "import pandas as pd\n",
        "import enum\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from preprocessing import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1bc0a51b49a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPOAzdU1Svtc"
      },
      "source": [
        "def plot_graph(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_' + string], '')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_' + string])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYkwqfgSv2n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF1udyFtSv9B",
        "outputId": "a8600a4c-169c-416e-e945-bd7fb2ec2008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98 99 100\n",
            "bcd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDRrhhUTdrPk"
      },
      "source": [
        "## mask 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTOfyv7SwBg"
      },
      "source": [
        "# sequence를 받아서 패딩\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32) # seq중 0을 기준으로 bool로 바꾼후 0으로 casting\n",
        "\n",
        "  return seq[:, tf.mewaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpyOPIfjOgM4"
      },
      "source": [
        "def create_look_ahead_mask(size): # mask의 사이즈를 parameter로 받음\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones(size, size), -1, 0) # 하삼각행렬로 변환\n",
        "\n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pFhs4FaOgPQ"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  enc_padding_mask = create_padding_mask(inp) # 인코더 패딩 마스크\n",
        "  dec_padding_mask = create_padding_mask(inp) # 디코더 패딩 마스크\n",
        "\n",
        "  # 디코더에 대한 마스크는 하삼각행렬을...\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fln-Db3Vc-l0"
      },
      "source": [
        "## positional encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO1e51nKOgT9"
      },
      "source": [
        "# 위치별 각도를 얻는 함수\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * i / 2) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWwMR39lOgYq"
      },
      "source": [
        "# 최종 포지셔널 인코딩\n",
        "def positional_encoding(position, d_model): # position과 d_model을 parameter로 받음\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # 짝수는 sine 함수를 이용한 pos encoding\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # 홀수는 cosine 함수를 이용한 pos encoding\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaixs, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype = tf.float32) # pos encoding을 실수로 casting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXlstOwAie8B"
      },
      "source": [
        "## Scaled dot product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcNwJXqBSv0B"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b = True) # key에 대해서 matmul 이전 transposed\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape()[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add!!!!\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9) # 큰 음수를 곱해줘서 mask화 시키도록함....\n",
        "\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # softmax 적용\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # matmul 적용\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEjfhFI2ih2Q"
      },
      "source": [
        "## Multihead Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQwrUQM-s2N4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgRS_WA2imby"
      },
      "source": [
        "## Feed forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXONtsgpSvrH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7mr61kuisDG"
      },
      "source": [
        "# Encoder layer\n",
        "(MHA, FFN, norm, dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s319JWynirx-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFcOKosViuhU"
      },
      "source": [
        "## Decoder layer\n",
        "(MHA, FFN, norm, dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4dKxvS4jEC8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK7ofTEdjfrK"
      },
      "source": [
        "## Encoder\n",
        "(Embedding, ENC_layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvg0hvMriuUd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_V0gW1pjpb8"
      },
      "source": [
        "## Decoder\n",
        "(Embedding, DEC_layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrWT3eG2jp6x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed7d0S4pkX7t"
      },
      "source": [
        "## Transformer\n",
        "(Encoder, Decoder, final_layer) + inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnUwBcPWkXpV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvAa83rjk9Vq"
      },
      "source": [
        "## loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntJ6tzkakXdO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPQPmpcflBMG"
      },
      "source": [
        "## model compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngPHOzBAlFBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzpTQTCBlFbD"
      },
      "source": [
        "## early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y188WrPWlFyG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
